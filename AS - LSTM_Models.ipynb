{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874353f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85904e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "\n",
    "from projectwind.data import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce66ae4",
   "metadata": {},
   "source": [
    "# LSTM_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(25)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26810d10",
   "metadata": {},
   "source": [
    "data = clean_timesteps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caf655",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Quick check on number of NaN over the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c984ae",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count number of na\n",
    "isna_df = data[0].isna().sum(axis=1) / len(data[0].columns)\n",
    "\n",
    "# Resample on daily basis\n",
    "daily_data = isna_df.resample('D').sum() / 6 # divide by # periods to get ~ 24hr % missing values\n",
    "\n",
    "# Graph output\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "plt.bar(x=daily_data.index, height=daily_data.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9f7dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Good to see there are less missing values towards end of data \n",
    "# (meaning test and validation sets should be of better quality than train set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f1e5d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfefdd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Interpolate all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa206508",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import clean_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090747b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_data = clean_LSTM_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d6491",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create wind speed & direction vectors and misalignment to average wind farm vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6aa48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Average wind speeds & directions over the wind turbines\n",
    "wind_speeds = pd.DataFrame()\n",
    "nacelle_dir = pd.DataFrame()\n",
    "misalignment = pd.DataFrame()\n",
    "for idx, WTG_data in enumerate(data):\n",
    "    wind_speeds[idx] = WTG_data['Wind Speed']\n",
    "    nacelle_dir[idx] = WTG_data['Nacelle Orientation']\n",
    "    misalignment[idx] = WTG_data['Misalignment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed85d68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in misalignment:\n",
    "    misalignment[idx] = misalignment[idx].apply(lambda x: x if x <=180 else (360 - x)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0f3a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wind_dir = pd.DataFrame()\n",
    "for idx in misalignment:\n",
    "    wind_dir[idx] = nacelle_dir[idx] - misalignment[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3eb75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i in range(len(nacelle_dir.columns)):\n",
    "    row, col = i//5, i%5\n",
    "    axes[row,col].hist2d(wind_dir[i], wind_speeds[i], bins=(50, 50), vmax=400)\n",
    "    plt.xlabel('Wind Direction [deg]')\n",
    "    plt.ylabel('Wind Velocity [m/s]');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a27e1cb2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Creates data leakage!\n",
    "average = pd.DataFrame(index=nacelle_dir.index)\n",
    "average['wind_dir'] = wind_dir.mean(axis=1)\n",
    "average['wind_speeds'] = wind_speeds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca8afd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wind_X_vector = pd.DataFrame()\n",
    "wind_Y_vector = pd.DataFrame()\n",
    "for idx in wind_dir:\n",
    "    wind_dir[idx] = wind_dir[idx] * np.pi / 180 # convert to radians\n",
    "    wind_X_vector[idx] = wind_speeds[idx] * np.cos(wind_dir[idx])  # get X vector\n",
    "    wind_Y_vector[idx] = wind_speeds[idx] * np.sin(wind_dir[idx])  # get Y vector\n",
    "    wind_X_vector[idx] = wind_speeds[idx] * np.cos(wind_dir[idx])  # get X vector\n",
    "    wind_Y_vector[idx] = wind_speeds[idx] * np.sin(wind_dir[idx])  # get Y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ba4eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i in range(len(nacelle_dir.columns)):\n",
    "    row, col = i//5, i%5\n",
    "    axes[row,col].hist2d(wind_X_vector[i], wind_Y_vector[i], bins=(50, 50), vmax=400)\n",
    "    plt.xlabel('Wind X [m/s]')\n",
    "    plt.ylabel('Wind Y [m/s]');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a0dc160",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Creates data leakage!\n",
    "average['wind_dir_rad'] = average['wind_dir'] * np.pi / 180 # convert to radians\n",
    "average['X_vector'] = average['wind_speeds'] * np.cos(average['wind_dir_rad'])  # get X vector\n",
    "average['Y_vector'] = average['wind_speeds'] * np.sin(average['wind_dir_rad'])  # get Y vector"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43625e07",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.hist2d(average['wind_dir'], average['wind_speeds'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]');"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d023778",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.hist2d(average['X_vector'], average['Y_vector'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cf61b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx, WTG_data in enumerate(data):\n",
    "    WTG_data['WTG_wind_X'] = wind_X_vector[idx]\n",
    "    WTG_data['WTG_wind_Y'] = wind_Y_vector[idx]\n",
    "#     WTG_data['Misalign_wind_X'] = average['X_vector'] - wind_X_vector[idx] # Creates data leakage!\n",
    "#     WTG_data['Misalign_wind_Y'] = average['Y_vector'] - wind_Y_vector[idx] # Creates data leakage!\n",
    "    WTG_data.drop(columns=['Misalignment','Nacelle Orientation'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0d947",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Power vs. Rotor Speed check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d616a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = data[19].loc['2020-03-05':'2020-03-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c24ea8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.lineplot(x=temp.index, y=temp['Power']/150)\n",
    "sns.lineplot(x=temp.index, y=temp['Rotor Speed'])\n",
    "sns.lineplot(x=temp.index, y=temp['Wind Speed'])\n",
    "fig.legend(['Power','Rotor Speed', 'Wind Speed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9fd66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sine/Cosine Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656ecbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=data[0].index)\n",
    "timestamp_s = data[0].index.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5f7c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.iloc[0:792,0])\n",
    "plt.plot(df.iloc[0:792,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb50bd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for WTG_data in data:\n",
    "    WTG_data['Day sin'] = df['Day sin']\n",
    "    WTG_data['Day cos'] = df['Day cos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81f5bd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f303a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = data[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07858dc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd4169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611529ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_std = (df - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fae0fa17",
   "metadata": {
    "hidden": true
   },
   "source": [
    "column_indices = {name: i for i, name in enumerate(data[0].columns)}\n",
    "\n",
    "n = len(data[0])\n",
    "train_df = []\n",
    "val_df = []\n",
    "test_df = []\n",
    "\n",
    "for WTG_data in data:\n",
    "    train_df.append(WTG_data[0:int(n*0.7)])\n",
    "    val_df.append(WTG_data[int(n*0.7):int(n*0.9)])\n",
    "    test_df.append(WTG_data[int(n*0.9):])\n",
    "\n",
    "num_features = data[0].shape[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fc34d70",
   "metadata": {
    "hidden": true
   },
   "source": [
    "train_mean = train_df[0].mean()\n",
    "train_std = train_df[0].std()\n",
    "\n",
    "train_df = (train_df[0] - train_mean) / train_std\n",
    "val_df = (val_df[0] - train_mean) / train_std\n",
    "test_df = (test_df[0] - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4f991",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed954ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc9b83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcad2c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d38cb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ea3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79418af5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
    "                     label_columns=df.columns)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85227832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w2 = WindowGenerator(input_width=24*5*6, label_width=12*6, shift=12*6,\n",
    "                     label_columns=['Power'])\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96459fd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e32ef1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c8ad8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "w2.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa09975",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in w2.train.take(25):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f196224",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in w2.train.take(100):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7f653",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = w2.train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e0114",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for sequence in dataset:\n",
    "    sequence.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4f101",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023cbfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0b83b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566ed06",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create window\n",
    "n_steps_in =  24 * 6     # 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df[0], val_df[0], test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d9ba5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(data):\n",
    "    X_datasets = []\n",
    "    y_datasets = []\n",
    "    \n",
    "    for WTG_data in data:\n",
    "        \n",
    "        # Find sequences according to window size of X and y\n",
    "        WTG_data = np.array(WTG_data, dtype=np.float32)\n",
    "        WTG_sequences = tf.keras.utils.timeseries_dataset_from_array(data=WTG_data,\n",
    "                                                                    targets=None,\n",
    "                                                                    sequence_length=window.total_window_size,\n",
    "                                                                    sampling_rate=1,\n",
    "                                                                    sequence_stride=window.total_window_size,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    batch_size=32)\n",
    "        # Split X and y according to window size\n",
    "        WTG_sequences = WTG_sequences.map(window.split_window)\n",
    "        \n",
    "        # Transfer from tensor to numpy array to save under .NPY format\n",
    "        X_datasets.append(chain.from_iterable([X.numpy() for X, y in WTG_sequences]))\n",
    "        y_datasets.append(chain.from_iterable([y.numpy() for X, y in WTG_sequences]))\n",
    "        \n",
    "    # Aggregate WTGs batches into same array\n",
    "    X_array = np.array(list(chain.from_iterable(X_datasets)))\n",
    "    y_array = np.array(list(chain.from_iterable(y_datasets)))\n",
    "    \n",
    "    #X_array, y_array = shuffle_sequences(X_array, y_array)\n",
    "        \n",
    "    return X_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fb8a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "X_train, y_train = make_dataset(train_df)\n",
    "X_val, y_val = make_dataset(val_df)\n",
    "X_test, y_test = make_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd2579",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape}, Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abe95b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shuffle_sequences(X, y, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9fac9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_sequences(X_train, y_train, seed=1)\n",
    "X_val, y_val = shuffle_sequences(X_val, y_val, seed=2)\n",
    "X_test, y_test = shuffle_sequences(X_test, y_test, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3d3db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape}, Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6f601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequence_name = f\"{window.input_width // 6}-{window.label_width//6}\"\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_train_{sequence_name}.npy', np.asanyarray(X_train, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_train_{sequence_name}.npy', np.asanyarray(y_train, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_val_{sequence_name}.npy', np.asanyarray(X_val, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_val_{sequence_name}.npy', np.asanyarray(y_val, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_test_{sequence_name}.npy', np.asanyarray(X_test, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_test_{sequence_name}.npy', np.asanyarray(y_test, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3891b8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = np.load(f'./projectwind/data/LSTM_sequence_train_datasets.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ec03e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4551136",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in train_ds:\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689355cd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test of python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275230a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddd78",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11213ae8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5bf20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in =  24 * 6     # 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df[0], val_df[0], test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0512bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in window.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba4481",
   "metadata": {},
   "source": [
    "# LSTM_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e48d1",
   "metadata": {},
   "source": [
    "## Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbce82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6eb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3337a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 5 * 24 * 6     # 5 day x 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6facf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = window.train\n",
    "val_ds = window.val\n",
    "test_ds = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b52f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape},  Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "675dc53e",
   "metadata": {},
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_datasets(n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122799c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create & Save 48h - 3hr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f1577",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53755486",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c552266",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 5 day x 24hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d82cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14094db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape},  Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7f55e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.save_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37f059",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd51a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_lstm_model, multi_window)\n",
    "\n",
    "multi_val_performance = multi_lstm_model.evaluate(window.val)\n",
    "multi_performance = multi_lstm_model.evaluate(window.test, verbose=0)\n",
    "multi_window.plot(multi_lstm_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447d6db",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM feedback_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c865cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        # First layer\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units) \n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True) #Wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        # Second layer\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        # Output layer\n",
    "        self.dense = tf.keras.layers.Dense(num_features)\n",
    "\n",
    "    def warmup(self, inputs):\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "        return prediction, state\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "\n",
    "        # Initialize the LSTM state.\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps.\n",
    "        for n in range(1, self.out_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "            # Add the prediction to the output.\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions\n",
    "\n",
    "    def compile_and_fit(model, window, patience=2):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        patience=patience,\n",
    "                                                        mode='min')\n",
    "\n",
    "        model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "        history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                          validation_data=window.val,\n",
    "                          callbacks=[early_stopping])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3e4a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in window.train.take(1):\n",
    "    num_features = inputs.shape[2]\n",
    "    n_steps_in = inputs.shape[1]\n",
    "    n_steps_out = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64351de2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=32, out_steps=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c87f6a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prediction, state = feedback_model.warmup(window.example[0])\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aac008",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model(window.example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ff533",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Output shape (batch, time, features): ', feedback_model(window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e8425",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "history = compile_and_fit(feedback_model, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d261f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbeaaf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_performance = feedback_model.evaluate(window.val)\n",
    "test_performance = feedback_model.evaluate(window.test, verbose=0)\n",
    "window.plot(feedback_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e1f52",
   "metadata": {},
   "source": [
    "## LSTM model concat with weather forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221161e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d120643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from projectwind.data import get_data\n",
    "from projectwind.LSTM_weather_forecast import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01361fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shmiggit/code/AmaurySalles/projectwind/raw_data\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc91096",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df, 'Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91317eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split weather data from main dfs\n",
    "train_wf = list()\n",
    "for df in train_df:\n",
    "    train_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)\n",
    "\n",
    "val_wf = list()\n",
    "for df in val_df:\n",
    "    val_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)\n",
    "    \n",
    "test_wf = list()\n",
    "for df in test_df:\n",
    "    test_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdc410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df, 'Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519048f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 18:20:56.333788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-13 18:20:56.384757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-02-13 18:20:56.393318: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-13 18:20:56.397039: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a549e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_wf, val_wf, test_wf, 'Wind Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9e7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wf, y_train_wf = window.train\n",
    "X_val_wf, y_val_wf = window.val\n",
    "X_test_wf, y_test_wf = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e0dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_model():\n",
    "    input_perf = tf.keras.layers.Input(shape=(n_steps_in, X_train.shape[2]))\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(input_perf)\n",
    "    output_perf = tf.keras.layers.LSTM(32, return_sequences=True)(x_seq)\n",
    "    x = tf.keras.layers.LSTM(32, return_sequences=False)(x_seq)\n",
    "    output_perf = tf.keras.layers.Dense(n_steps_out)(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_perf, outputs=output_perf)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c951a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 288, 7)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 288, 32)           5120      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                594       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,034\n",
      "Trainable params: 14,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "perf_model = performance_model()\n",
    "perf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65afa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_model():\n",
    "    input_fc = tf.keras.layers.Input(shape=(18,))  # Will only use y_forecast\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(input_fc)\n",
    "    output_fc = tf.keras.layers.Dense(18, activation=\"relu\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_fc, outputs=output_fc)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec365cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 18)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                608       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                594       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,202\n",
      "Trainable params: 1,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fc = forecast_model()\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed0da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "model_perf = performance_model() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_perf = model_perf.input\n",
    "output_perf = model_perf.output\n",
    "\n",
    "model_fc = forecast_model() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_fc = model_fc.input\n",
    "output_fc = model_fc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f1e5e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 288, 7) dtype=float32 (created by layer 'input_3')>,\n",
       " <KerasTensor: shape=(None, 18) dtype=float32 (created by layer 'dense_3')>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_perf, output_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33582a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 18) dtype=float32 (created by layer 'input_4')>,\n",
       " <KerasTensor: shape=(None, 18) dtype=float32 (created by layer 'dense_5')>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fc, output_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32ee16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two streams of data\n",
    "inputs = [input_perf, input_fc]\n",
    "\n",
    "combined = tf.keras.layers.concatenate([output_perf, output_fc])\n",
    "\n",
    "x = tf.keras.layers.Dense(n_steps_out, activation=\"relu\")(combined)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(n_steps_out, activation=\"linear\")(x)\n",
    "\n",
    "model_combined = tf.keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2810150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 288, 7)]     0           []                               \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 288, 32)      5120        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 18)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 32)           8320        ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           608         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 18)           594         ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 18)           594         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 36)           0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 18)           666         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 18)           342         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,244\n",
      "Trainable params: 16,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f6a7558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bbe6728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289, 288, 7), (289, 18), (289, 18, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train_wf2.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "897a5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_wf2 = y_train_wf.reshape((289,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ed4ecd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 288, 7), (82, 18, 1), (82, 18, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val_wf.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62c67e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "model_perf.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "model_combined.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1065626d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 13s 924ms/step - loss: 801.4457 - mae: 801.9449\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 11s 1s/step - loss: 793.1769 - mae: 793.6763\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 782.8503 - mae: 783.3495\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 767.7427 - mae: 768.2424\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 10s 964ms/step - loss: 746.8420 - mae: 747.3416\n",
      "Epoch 6/10\n",
      " 1/10 [==>...........................] - ETA: 8s - loss: 738.2126 - mae: 738.7126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      4\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_wf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/wind/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model_combined.fit(x=[X_train, y_train_wf],y=y_train,\n",
    "                            epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8ba21",
   "metadata": {},
   "source": [
    "### Combined Model _v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20450a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04d77697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model():\n",
    "    input_perf = tf.keras.layers.Input(shape=(n_steps_in, X_train.shape[2]))\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(input_perf)\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(x_seq)\n",
    "    x_perf = tf.keras.layers.LSTM(32, return_sequences=False)(x_seq)\n",
    "    #x_perf = tf.keras.layers.Reshape((32*X_train.shape[1],))(x_perf)\n",
    "    input_fc = tf.keras.layers.Input(shape=(18,))\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(input_fc)\n",
    "    x_fc = tf.keras.layers.Dense(18, activation=\"relu\")(x)\n",
    "    \n",
    "    combined = tf.keras.layers.concatenate([x_perf, x_fc])\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(combined)\n",
    "    outputs = tf.keras.layers.Dense(n_steps_out, activation=\"linear\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_perf, input_fc], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55bdc667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)          [(None, 288, 7)]     0           []                               \n",
      "                                                                                                  \n",
      " lstm_51 (LSTM)                 (None, 288, 32)      5120        ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 18)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_52 (LSTM)                 (None, 288, 32)      8320        ['lstm_51[0][0]']                \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 32)           608         ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_53 (LSTM)                 (None, 32)           8320        ['lstm_52[0][0]']                \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 18)           594         ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 50)           0           ['lstm_53[0][0]',                \n",
      "                                                                  'dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 64)           3264        ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 18)           1170        ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,396\n",
      "Trainable params: 27,396\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h_model=hybrid_model()\n",
    "h_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "687279ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_model.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8fa3571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 22s 1s/step - loss: 810.4244 - mae: 810.9238\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 809.7098 - mae: 810.2091\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 809.1231 - mae: 809.6224\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 808.2883 - mae: 808.7877\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 13s 1s/step - loss: 806.7499 - mae: 807.2493\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 13s 1s/step - loss: 803.9781 - mae: 804.4775\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 13s 1s/step - loss: 798.9161 - mae: 799.4158\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 13s 1s/step - loss: 790.0593 - mae: 790.5590\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 774.9661 - mae: 775.4657\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 13s 1s/step - loss: 750.3945 - mae: 750.8943\n"
     ]
    }
   ],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = h_model.fit(x=[X_train, y_train_wf],y=y_train,\n",
    "                            epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693b490",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tutorial LSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0718f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30f464",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efde79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create window\n",
    "n_steps_in =  48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    # 3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae3ab7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbd551",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_ex, y_ex = window.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fbac2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(input_shape=(n_steps_in, len(window.column_indices))),\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(n_steps_out),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([n_steps_out, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eea80d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=5,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9c966",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_lstm_model, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9315eda",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_performance = multi_lstm_model.evaluate(X_val, y_val)\n",
    "test_performance = multi_lstm_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005a5cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.plot(multi_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4091a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.trainer import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d97bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b721c8a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD - LSTM_data_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83085ccd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data = get_data(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ffe4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b933d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1986e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = clean_timesteps(raw_data)\n",
    "data = clean_LSTM_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caea234",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## clean_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad535dc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f13807",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_with_nan = temp_data[temp_data.isna().any(axis=1) == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cc9ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc[index_with_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972b773",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc['2019-05-06 09:30':'2019-05-06 15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9a11b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc['2019-05-06 09:30':'2019-05-06 15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db529d7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for WTG_data in data:\n",
    "    print(WTG_data.isna().sum().sum())\n",
    "    WTG_data.interpolate(axis=0, inplace=True)\n",
    "    print(WTG_data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cebdc8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  split_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d769e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f337c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a7efa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_len = int(24 * 6 * 5.5)\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4834ce1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find number of seq possible\n",
    "seq_num = len(data[0]) // (720+72) # per turbine\n",
    "seq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3a476",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_seq_len = int(0.2 * seq_num) # last 20% indices will belong to test set\n",
    "val_seq_len  = int(0.2 * seq_num) # 2nd last 20% indices will belong to val set\n",
    "test_seq_len, val_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4310c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_seq_start = seq_num - test_seq_len\n",
    "val_seq_start = seq_num - test_seq_len - val_seq_len\n",
    "0, val_seq_start, test_seq_start, 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0901",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_idx_start = test_seq_start * seq_len\n",
    "val_idx_start = val_seq_start * seq_len\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556cd3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "test_idx_start = int((seq_num - (seq_num * 0.2)) * seq_len)\n",
    "val_idx_start = int((seq_num - (seq_num * 0.4)) * seq_len)\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e724a2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "seq_len = int(24 * 6 * 5.5)\n",
    "seq_num = len(data[0]) // (720+72) # per turbine\n",
    "test_idx_start = int(seq_num * (0.8 * seq_len))\n",
    "val_idx_start = int(seq_num * (0.6 * seq_len))\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53debe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp.iloc[val_idx_start:test_idx_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b359763",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "from projectwind.LSTM_preproc import split_train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c45b6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val, test = split_train_val_test_split(data, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaf9e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee999a16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## get_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d0d0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import get_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774fafb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences = get_sequences(train, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a1705",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b40cae",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## extract_target_from_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7388be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = {'train':[1,2,3], 'val':[4,5], 'test':[6,7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a099716",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = dict(train=[1,2,3], val=[4,5], test=[6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceef80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1d9d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name, data in datasets.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1013cf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import extract_target_from_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c36fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4127c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, Y = extract_target_from_sequences(sequences, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b5304",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## init_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdbb44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import init_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79d80f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = init_LSTM_data(1, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4f16d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ac8b7",
   "metadata": {},
   "source": [
    "# OLD - Trainer_LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = np.load(f'./projectwind/data/LSTM_sequence_train_datasets.npy', allow_pickle=True)\n",
    "val_ds = np.load(f'./projectwind/data/LSTM_sequence_val_datasets.npy', allow_pickle=True)\n",
    "test_ds = np.load(f'./projectwind/data/LSTM_sequence_test_datasets.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baae5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectwind.LSTM_model import init_LSTM_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_LSTM_model(n_steps_in, n_steps_out, n_features):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
    "    model.add(Dense(n_steps_out, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_LSTM_model(n_steps_in=window.input_width, \n",
    "                        n_steps_out=window.label_width, \n",
    "                        n_features=len(window.column_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bba481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "window.plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ef047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(window.train,\n",
    "                    validation_data=window.val,\n",
    "                    epochs=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450eea5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(window.train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectwind.trainer import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f14bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "298252f2",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1876b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d79e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
