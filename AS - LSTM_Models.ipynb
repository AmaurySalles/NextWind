{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874353f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85904e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "\n",
    "from projectwind.data import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce66ae4",
   "metadata": {},
   "source": [
    "# LSTM_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(25)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26810d10",
   "metadata": {},
   "source": [
    "data = clean_timesteps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caf655",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Quick check on number of NaN over the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c984ae",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count number of na\n",
    "isna_df = data[0].isna().sum(axis=1) / len(data[0].columns)\n",
    "\n",
    "# Resample on daily basis\n",
    "daily_data = isna_df.resample('D').sum() / 6 # divide by # periods to get ~ 24hr % missing values\n",
    "\n",
    "# Graph output\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "plt.bar(x=daily_data.index, height=daily_data.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9f7dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Good to see there are less missing values towards end of data \n",
    "# (meaning test and validation sets should be of better quality than train set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f1e5d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfefdd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Interpolate all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa206508",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import clean_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090747b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_data = clean_LSTM_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d6491",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create wind speed & direction vectors and misalignment to average wind farm vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6aa48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Average wind speeds & directions over the wind turbines\n",
    "wind_speeds = pd.DataFrame()\n",
    "nacelle_dir = pd.DataFrame()\n",
    "misalignment = pd.DataFrame()\n",
    "for idx, WTG_data in enumerate(data):\n",
    "    wind_speeds[idx] = WTG_data['Wind Speed']\n",
    "    nacelle_dir[idx] = WTG_data['Nacelle Orientation']\n",
    "    misalignment[idx] = WTG_data['Misalignment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed85d68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in misalignment:\n",
    "    misalignment[idx] = misalignment[idx].apply(lambda x: x if x <=180 else (360 - x)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0f3a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wind_dir = pd.DataFrame()\n",
    "for idx in misalignment:\n",
    "    wind_dir[idx] = nacelle_dir[idx] - misalignment[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3eb75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i in range(len(nacelle_dir.columns)):\n",
    "    row, col = i//5, i%5\n",
    "    axes[row,col].hist2d(wind_dir[i], wind_speeds[i], bins=(50, 50), vmax=400)\n",
    "    plt.xlabel('Wind Direction [deg]')\n",
    "    plt.ylabel('Wind Velocity [m/s]');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a27e1cb2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Creates data leakage!\n",
    "average = pd.DataFrame(index=nacelle_dir.index)\n",
    "average['wind_dir'] = wind_dir.mean(axis=1)\n",
    "average['wind_speeds'] = wind_speeds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca8afd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wind_X_vector = pd.DataFrame()\n",
    "wind_Y_vector = pd.DataFrame()\n",
    "for idx in wind_dir:\n",
    "    wind_dir[idx] = wind_dir[idx] * np.pi / 180 # convert to radians\n",
    "    wind_X_vector[idx] = wind_speeds[idx] * np.cos(wind_dir[idx])  # get X vector\n",
    "    wind_Y_vector[idx] = wind_speeds[idx] * np.sin(wind_dir[idx])  # get Y vector\n",
    "    wind_X_vector[idx] = wind_speeds[idx] * np.cos(wind_dir[idx])  # get X vector\n",
    "    wind_Y_vector[idx] = wind_speeds[idx] * np.sin(wind_dir[idx])  # get Y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ba4eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i in range(len(nacelle_dir.columns)):\n",
    "    row, col = i//5, i%5\n",
    "    axes[row,col].hist2d(wind_X_vector[i], wind_Y_vector[i], bins=(50, 50), vmax=400)\n",
    "    plt.xlabel('Wind X [m/s]')\n",
    "    plt.ylabel('Wind Y [m/s]');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a0dc160",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Creates data leakage!\n",
    "average['wind_dir_rad'] = average['wind_dir'] * np.pi / 180 # convert to radians\n",
    "average['X_vector'] = average['wind_speeds'] * np.cos(average['wind_dir_rad'])  # get X vector\n",
    "average['Y_vector'] = average['wind_speeds'] * np.sin(average['wind_dir_rad'])  # get Y vector"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43625e07",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.hist2d(average['wind_dir'], average['wind_speeds'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]');"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d023778",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.hist2d(average['X_vector'], average['Y_vector'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cf61b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx, WTG_data in enumerate(data):\n",
    "    WTG_data['WTG_wind_X'] = wind_X_vector[idx]\n",
    "    WTG_data['WTG_wind_Y'] = wind_Y_vector[idx]\n",
    "#     WTG_data['Misalign_wind_X'] = average['X_vector'] - wind_X_vector[idx] # Creates data leakage!\n",
    "#     WTG_data['Misalign_wind_Y'] = average['Y_vector'] - wind_Y_vector[idx] # Creates data leakage!\n",
    "    WTG_data.drop(columns=['Misalignment','Nacelle Orientation'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0d947",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Power vs. Rotor Speed check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d616a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = data[19].loc['2020-03-05':'2020-03-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c24ea8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.lineplot(x=temp.index, y=temp['Power']/150)\n",
    "sns.lineplot(x=temp.index, y=temp['Rotor Speed'])\n",
    "sns.lineplot(x=temp.index, y=temp['Wind Speed'])\n",
    "fig.legend(['Power','Rotor Speed', 'Wind Speed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9fd66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sine/Cosine Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656ecbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=data[0].index)\n",
    "timestamp_s = data[0].index.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5f7c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.iloc[0:792,0])\n",
    "plt.plot(df.iloc[0:792,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb50bd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for WTG_data in data:\n",
    "    WTG_data['Day sin'] = df['Day sin']\n",
    "    WTG_data['Day cos'] = df['Day cos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81f5bd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f303a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = data[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07858dc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd4169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611529ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_std = (df - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fae0fa17",
   "metadata": {
    "hidden": true
   },
   "source": [
    "column_indices = {name: i for i, name in enumerate(data[0].columns)}\n",
    "\n",
    "n = len(data[0])\n",
    "train_df = []\n",
    "val_df = []\n",
    "test_df = []\n",
    "\n",
    "for WTG_data in data:\n",
    "    train_df.append(WTG_data[0:int(n*0.7)])\n",
    "    val_df.append(WTG_data[int(n*0.7):int(n*0.9)])\n",
    "    test_df.append(WTG_data[int(n*0.9):])\n",
    "\n",
    "num_features = data[0].shape[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fc34d70",
   "metadata": {
    "hidden": true
   },
   "source": [
    "train_mean = train_df[0].mean()\n",
    "train_std = train_df[0].std()\n",
    "\n",
    "train_df = (train_df[0] - train_mean) / train_std\n",
    "val_df = (val_df[0] - train_mean) / train_std\n",
    "test_df = (test_df[0] - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4f991",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed954ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc9b83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcad2c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d38cb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ea3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79418af5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
    "                     label_columns=df.columns)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85227832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w2 = WindowGenerator(input_width=24*5*6, label_width=12*6, shift=12*6,\n",
    "                     label_columns=['Power'])\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96459fd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e32ef1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c8ad8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "w2.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa09975",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in w2.train.take(25):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f196224",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in w2.train.take(100):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7f653",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = w2.train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e0114",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for sequence in dataset:\n",
    "    sequence.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4f101",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023cbfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0b83b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a74569",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create window\n",
    "n_steps_in =  24 * 6     # 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df[0], val_df[0], test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d9ba5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(data):\n",
    "    X_datasets = []\n",
    "    y_datasets = []\n",
    "    \n",
    "    for WTG_data in data:\n",
    "        \n",
    "        # Find sequences according to window size of X and y\n",
    "        WTG_data = np.array(WTG_data, dtype=np.float32)\n",
    "        WTG_sequences = tf.keras.utils.timeseries_dataset_from_array(data=WTG_data,\n",
    "                                                                    targets=None,\n",
    "                                                                    sequence_length=window.total_window_size,\n",
    "                                                                    sampling_rate=1,\n",
    "                                                                    sequence_stride=window.total_window_size,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    batch_size=32)\n",
    "        # Split X and y according to window size\n",
    "        WTG_sequences = WTG_sequences.map(window.split_window)\n",
    "        \n",
    "        # Transfer from tensor to numpy array to save under .NPY format\n",
    "        X_datasets.append(chain.from_iterable([X.numpy() for X, y in WTG_sequences]))\n",
    "        y_datasets.append(chain.from_iterable([y.numpy() for X, y in WTG_sequences]))\n",
    "        \n",
    "    # Aggregate WTGs batches into same array\n",
    "    X_array = np.array(list(chain.from_iterable(X_datasets)))\n",
    "    y_array = np.array(list(chain.from_iterable(y_datasets)))\n",
    "    \n",
    "    #X_array, y_array = shuffle_sequences(X_array, y_array)\n",
    "        \n",
    "    return X_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fb8a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "X_train, y_train = make_dataset(train_df)\n",
    "X_val, y_val = make_dataset(val_df)\n",
    "X_test, y_test = make_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd2579",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape}, Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abe95b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shuffle_sequences(X, y, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9fac9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_sequences(X_train, y_train, seed=1)\n",
    "X_val, y_val = shuffle_sequences(X_val, y_val, seed=2)\n",
    "X_test, y_test = shuffle_sequences(X_test, y_test, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498a64a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape}, Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6f601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequence_name = f\"{window.input_width // 6}-{window.label_width//6}\"\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_train_{sequence_name}.npy', np.asanyarray(X_train, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_train_{sequence_name}.npy', np.asanyarray(y_train, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_val_{sequence_name}.npy', np.asanyarray(X_val, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_val_{sequence_name}.npy', np.asanyarray(y_val, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_test_{sequence_name}.npy', np.asanyarray(X_test, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_test_{sequence_name}.npy', np.asanyarray(y_test, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3891b8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = np.load(f'./projectwind/data/LSTM_sequence_train_datasets.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ec03e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4551136",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in train_ds:\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689355cd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test of python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275230a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddd78",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11213ae8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5bf20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in =  24 * 6     # 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df[0], val_df[0], test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0512bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in window.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba4481",
   "metadata": {},
   "source": [
    "# LSTM_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db888b",
   "metadata": {},
   "source": [
    "## Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fa2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39faf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6eb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1720414",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 5 * 24 * 6     # 5 day x 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fde9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = window.train\n",
    "val_ds = window.val\n",
    "test_ds = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7118282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98614adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape},  Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7256494",
   "metadata": {},
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_datasets(n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bc327",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create & Save 48h - 3hr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93265ed5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f6572",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d1da3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 5 day x 24hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68872fb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6f0ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape},  Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b253690",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.save_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a3c1f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcdc4f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_lstm_model, multi_window)\n",
    "\n",
    "multi_val_performance = multi_lstm_model.evaluate(window.val)\n",
    "multi_performance = multi_lstm_model.evaluate(window.test, verbose=0)\n",
    "multi_window.plot(multi_lstm_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7cc31",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM feedback_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae74deb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        # First layer\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units) \n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True) #Wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        # Second layer\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        # Output layer\n",
    "        self.dense = tf.keras.layers.Dense(num_features)\n",
    "\n",
    "    def warmup(self, inputs):\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "        return prediction, state\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "\n",
    "        # Initialize the LSTM state.\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps.\n",
    "        for n in range(1, self.out_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "            # Add the prediction to the output.\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions\n",
    "\n",
    "    def compile_and_fit(model, window, patience=2):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        patience=patience,\n",
    "                                                        mode='min')\n",
    "\n",
    "        model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "        history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                          validation_data=window.val,\n",
    "                          callbacks=[early_stopping])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d157ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in window.train.take(1):\n",
    "    num_features = inputs.shape[2]\n",
    "    n_steps_in = inputs.shape[1]\n",
    "    n_steps_out = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cedcf8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=32, out_steps=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e67a8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prediction, state = feedback_model.warmup(window.example[0])\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac276a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model(window.example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68af860",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Output shape (batch, time, features): ', feedback_model(window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be6d6f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "history = compile_and_fit(feedback_model, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb4712",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c8e2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_performance = feedback_model.evaluate(window.val)\n",
    "test_performance = feedback_model.evaluate(window.test, verbose=0)\n",
    "window.plot(feedback_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1001f",
   "metadata": {},
   "source": [
    "## Revising Window_Split to include forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3621bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4777aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "\n",
    "from projectwind.LSTM_weather_forecast import get_LSTM_data, WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c508f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "### Fetching Forecast from API ###\n",
      "### Loaded Forecast from API ###\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac6d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 87140 entries, 2019-05-05 00:00:00 to 2020-12-30 19:50:00\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Power        87140 non-null  float64\n",
      " 1   Rotor Speed  87140 non-null  float64\n",
      " 2   Blade Pitch  87140 non-null  float64\n",
      " 3   Nacelle_X    87140 non-null  float64\n",
      " 4   Nacelle_Y    87140 non-null  float64\n",
      " 5   Wind_X       87140 non-null  float64\n",
      " 6   Wind_Y       87140 non-null  float64\n",
      " 7   Day sin      87140 non-null  float64\n",
      " 8   Day cos      87140 non-null  float64\n",
      " 9   tempC        87140 non-null  float32\n",
      " 10  precipMM     87140 non-null  float32\n",
      " 11  Wind_API_X   87140 non-null  float32\n",
      " 12  Wind_API_Y   87140 non-null  float32\n",
      "dtypes: float32(4), float64(9)\n",
      "memory usage: 8.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_df[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf82a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6  # 48hrs x 6x10min timesteps\n",
    "n_steps_out = 3 * 6  # 3hrs x 6x10min timesteps\n",
    "\n",
    "window = WindowGenerator(input_width=n_steps_in, label_width=n_steps_out, shift=n_steps_out,\n",
    "                         train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                         forecast_columns=['tempC','precipMM','Wind_API_X','Wind_API_Y'],label_columns=['Power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f94abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_fc_train, y_train, = window.make_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e506206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((568, 288, 13), (568, 18, 4), (568, 18, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_fc_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0053c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_fc_val, y_val, = window.make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24261330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162, 288, 13), (162, 18, 4), (162, 18, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, X_fc_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7792ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_fc_test, y_test, = window.make_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77626a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 288, 13), (80, 18, 4), (80, 18, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_fc_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61c91509",
   "metadata": {},
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df, val_df, test_df, \n",
    "                 forecast_columns=None, label_columns=None):\n",
    "\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df[0].columns)}\n",
    "        \n",
    "        # Work out the forecast column indices.\n",
    "        self.forecast_columns = forecast_columns\n",
    "        if forecast_columns is not None:\n",
    "            self.forecast_columns_indices = {name: i for i, name in enumerate(forecast_columns)}\n",
    "        self.forecast_indices = {name: i for i, name in enumerate(train_df[0].columns)}\n",
    "        \n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.forecast_width = label_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        # Work out window slices\n",
    "        self.total_window_size = input_width + shift\n",
    "        # Inputs\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        # Forecast\n",
    "        self.forecast_start = self.total_window_size - self.forecast_width\n",
    "        self.forecast_slice = slice(self.forecast_start, None)\n",
    "        self.forecast_indices = np.arange(self.total_window_size)[self.forecast_slice]\n",
    "        # Label\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Forecast column name(s): {self.forecast_columns}',            \n",
    "            f'Forecast indices: {self.forecast_indices}',\n",
    "            f'Label column name(s): {self.label_columns}',\n",
    "            f'Label indices: {self.label_indices}'])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef9fd524",
   "metadata": {},
   "source": [
    "def split_windows(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    forecast = features[:, self.forecast_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    \n",
    "    # If forecast & labels, stack window output together\n",
    "    if self.forecast_columns is not None:\n",
    "        forecast = tf.stack([forecast[:,:, self.column_indices[name]] for name in self.forecast_columns],\n",
    "                          axis=-1)\n",
    "    \n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack([labels[:,:, self.column_indices[name]] for name in self.label_columns],\n",
    "                          axis=-1)\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    forecast.set_shape([None, self.forecast_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, forecast, labels\n",
    "\n",
    "WindowGenerator.split_windows = split_windows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f902006b",
   "metadata": {},
   "source": [
    "def make_dataset(self, data):\n",
    "    X_datasets = []\n",
    "    X_fc_datasets = []\n",
    "    y_datasets = []\n",
    "\n",
    "    for WTG_data in data:\n",
    "\n",
    "        # Find sequences according to window size of X and y\n",
    "        WTG_data = np.array(WTG_data, dtype=np.float32)\n",
    "        WTG_sequences = tf.keras.utils.timeseries_dataset_from_array(data=WTG_data,\n",
    "                                                                    targets=None,\n",
    "                                                                    sequence_length=self.total_window_size,\n",
    "                                                                    sampling_rate=1,\n",
    "                                                                    sequence_stride=self.total_window_size,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    batch_size=32)\n",
    "        # Split X and y according to window size\n",
    "        WTG_sequences = WTG_sequences.map(self.split_windows)\n",
    "\n",
    "        # Transfer from tensor to numpy array to save under .NPY format\n",
    "        X_datasets.append(chain.from_iterable([X.numpy() for X, X_fc, y in WTG_sequences]))\n",
    "        X_fc_datasets.append(chain.from_iterable([X_fc.numpy() for X, X_fc, y in WTG_sequences]))\n",
    "        y_datasets.append(chain.from_iterable([y.numpy() for X, X_fc, y in WTG_sequences]))\n",
    "\n",
    "    # Aggregate WTGs batches into same array\n",
    "    X_array = np.array(list(chain.from_iterable(X_datasets)))\n",
    "    X_fc_array = np.array(list(chain.from_iterable(X_fc_datasets)))\n",
    "    y_array = np.array(list(chain.from_iterable(y_datasets)))\n",
    "\n",
    "    X_array, X_fc_array, y_array = self.shuffle_sequences(X_array, X_fc_array, y_array)\n",
    "\n",
    "    return X_array, X_fc_array, y_array\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad175fac",
   "metadata": {},
   "source": [
    "def shuffle_sequences(self, X, X_fc, y, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X_fc)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    return X, X_fc, y\n",
    "\n",
    "WindowGenerator.shuffle_sequences = shuffle_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b916e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM model concat with weather forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73171c9d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023fe08",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from projectwind.data import get_data\n",
    "from projectwind.LSTM_weather_forecast import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff940ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c5aeb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df, 'Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e176b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split weather data from main dfs\n",
    "train_wf = list()\n",
    "for df in train_df:\n",
    "    train_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)\n",
    "\n",
    "val_wf = list()\n",
    "for df in val_df:\n",
    "    val_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)\n",
    "    \n",
    "test_wf = list()\n",
    "for df in test_df:\n",
    "    test_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704b19f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df, 'Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9cb6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66dfb5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_wf, val_wf, test_wf, 'Wind Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759d2c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_wf, y_train_wf = window.train\n",
    "X_val_wf, y_val_wf = window.val\n",
    "X_test_wf, y_test_wf = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4fa55e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def performance_model():\n",
    "    input_perf = tf.keras.layers.Input(shape=(n_steps_in, X_train.shape[2]))\n",
    "    x_state = tf.keras.layers.LSTM(32, return_sequences=True)(input_perf)\n",
    "    x_state = tf.keras.layers.LSTM(32, return_sequences=True)(x_state)\n",
    "    x = tf.keras.layers.LSTM(32, return_sequences=False)(x_state)\n",
    "    output_perf = tf.keras.layers.Dense(n_steps_out)(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_perf, outputs=output_perf)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49700f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf_model = performance_model()\n",
    "perf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6672cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def forecast_model():\n",
    "    input_fc = tf.keras.layers.Input(shape=(18,))  # Will only use y_forecast\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(input_fc)\n",
    "    output_fc = tf.keras.layers.Dense(18, activation=\"relu\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_fc, outputs=output_fc)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0a9a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc = forecast_model()\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82217d7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Combined model\n",
    "model_perf = performance_model() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_perf = model_perf.input\n",
    "output_perf = model_perf.output\n",
    "\n",
    "model_fc = forecast_model() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_fc = model_fc.input\n",
    "output_fc = model_fc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017a5c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_perf, output_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15181114",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc, output_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d3f8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Combine the two streams of data\n",
    "inputs = [input_perf, input_fc]\n",
    "\n",
    "combined = tf.keras.layers.concatenate([output_perf, output_fc])\n",
    "\n",
    "x = tf.keras.layers.Dense(n_steps_out, activation=\"relu\")(combined)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(n_steps_out, activation=\"linear\")(x)\n",
    "\n",
    "model_combined = tf.keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2e826",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78983a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88e151",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train_wf2.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53427ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_wf2 = y_train_wf.reshape((289,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330b8ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val.shape, y_val_wf.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeede18a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "model_perf.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "model_combined.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3afc26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model_combined.fit(x=[X_train, y_train_wf],y=y_train,\n",
    "                            epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bb3a2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Combined Model _v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a4e35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a9fdd3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hybrid_model():\n",
    "    input_perf = tf.keras.layers.Input(shape=(n_steps_in, X_train.shape[2]))\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(input_perf)\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(x_seq)\n",
    "    x_perf = tf.keras.layers.LSTM(32, return_sequences=False)(x_seq)\n",
    "    #x_perf = tf.keras.layers.Reshape((32*X_train.shape[1],))(x_perf)\n",
    "    input_fc = tf.keras.layers.Input(shape=(18,))\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(input_fc)\n",
    "    x_fc = tf.keras.layers.Dense(18, activation=\"relu\")(x)\n",
    "    \n",
    "    combined = tf.keras.layers.concatenate([x_perf, x_fc])\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(combined)\n",
    "    outputs = tf.keras.layers.Dense(n_steps_out, activation=\"linear\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_perf, input_fc], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74db7104",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 288, 13)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 288, 32)      5888        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 18)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 288, 32)      8320        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           608         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 32)           8320        ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 18)           594         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 50)           0           ['lstm_2[0][0]',                 \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           3264        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 18)           1170        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,164\n",
      "Trainable params: 28,164\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h_model=hybrid_model()\n",
    "h_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fd605",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h_model.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56bc12",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = h_model.fit(x=[X_train, y_train_wf],y=y_train,\n",
    "                            epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b559ef8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9eb40a7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tutorial LSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc852b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c01a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db265b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create window\n",
    "n_steps_in =  48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    # 3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42504f2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768890a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_ex, y_ex = window.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a16647",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(input_shape=(n_steps_in, len(window.column_indices))),\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(n_steps_out),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([n_steps_out, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58f260",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=5,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a99ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_lstm_model, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53abf2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_performance = multi_lstm_model.evaluate(X_val, y_val)\n",
    "test_performance = multi_lstm_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88f964",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.plot(multi_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d930cf5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.trainer import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641c586",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b721c8a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD - LSTM_data_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83085ccd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data = get_data(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ffe4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b933d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1986e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = clean_timesteps(raw_data)\n",
    "data = clean_LSTM_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caea234",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## clean_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad535dc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f13807",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_with_nan = temp_data[temp_data.isna().any(axis=1) == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cc9ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc[index_with_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972b773",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc['2019-05-06 09:30':'2019-05-06 15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9a11b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc['2019-05-06 09:30':'2019-05-06 15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db529d7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for WTG_data in data:\n",
    "    print(WTG_data.isna().sum().sum())\n",
    "    WTG_data.interpolate(axis=0, inplace=True)\n",
    "    print(WTG_data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cebdc8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  split_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d769e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f337c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a7efa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_len = int(24 * 6 * 5.5)\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4834ce1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find number of seq possible\n",
    "seq_num = len(data[0]) // (720+72) # per turbine\n",
    "seq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3a476",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_seq_len = int(0.2 * seq_num) # last 20% indices will belong to test set\n",
    "val_seq_len  = int(0.2 * seq_num) # 2nd last 20% indices will belong to val set\n",
    "test_seq_len, val_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4310c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_seq_start = seq_num - test_seq_len\n",
    "val_seq_start = seq_num - test_seq_len - val_seq_len\n",
    "0, val_seq_start, test_seq_start, 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0901",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_idx_start = test_seq_start * seq_len\n",
    "val_idx_start = val_seq_start * seq_len\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556cd3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "test_idx_start = int((seq_num - (seq_num * 0.2)) * seq_len)\n",
    "val_idx_start = int((seq_num - (seq_num * 0.4)) * seq_len)\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e724a2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "seq_len = int(24 * 6 * 5.5)\n",
    "seq_num = len(data[0]) // (720+72) # per turbine\n",
    "test_idx_start = int(seq_num * (0.8 * seq_len))\n",
    "val_idx_start = int(seq_num * (0.6 * seq_len))\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53debe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp.iloc[val_idx_start:test_idx_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b359763",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "from projectwind.LSTM_preproc import split_train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c45b6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val, test = split_train_val_test_split(data, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaf9e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee999a16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## get_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d0d0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import get_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774fafb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences = get_sequences(train, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a1705",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b40cae",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## extract_target_from_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7388be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = {'train':[1,2,3], 'val':[4,5], 'test':[6,7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a099716",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = dict(train=[1,2,3], val=[4,5], test=[6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceef80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1d9d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name, data in datasets.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1013cf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import extract_target_from_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c36fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4127c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, Y = extract_target_from_sequences(sequences, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b5304",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## init_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdbb44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import init_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79d80f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = init_LSTM_data(1, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4f16d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ac8b7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD - Trainer_LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfc605",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = np.load(f'./projectwind/data/LSTM_sequence_train_datasets.npy', allow_pickle=True)\n",
    "val_ds = np.load(f'./projectwind/data/LSTM_sequence_val_datasets.npy', allow_pickle=True)\n",
    "test_ds = np.load(f'./projectwind/data/LSTM_sequence_test_datasets.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baae5d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_model import init_LSTM_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec718c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_LSTM_model(n_steps_in, n_steps_out, n_features):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
    "    model.add(Dense(n_steps_out, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a030f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = init_LSTM_model(n_steps_in=window.input_width, \n",
    "                        n_steps_out=window.label_width, \n",
    "                        n_features=len(window.column_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01646e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c88bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ede2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ef047",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MAE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(window.train,\n",
    "                    validation_data=window.val,\n",
    "                    epochs=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00561d77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e4577",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MSE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(window.train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332dbc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.trainer import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89cb26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f14bfe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "298252f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1876b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d79e49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
