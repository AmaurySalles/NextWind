{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874353f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85904e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "\n",
    "from projectwind.data import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce66ae4",
   "metadata": {},
   "source": [
    "# LSTM_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(25)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26810d10",
   "metadata": {},
   "source": [
    "data = clean_timesteps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caf655",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Quick check on number of NaN over the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c984ae",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count number of na\n",
    "isna_df = data[0].isna().sum(axis=1) / len(data[0].columns)\n",
    "\n",
    "# Resample on daily basis\n",
    "daily_data = isna_df.resample('D').sum() / 6 # divide by # periods to get ~ 24hr % missing values\n",
    "\n",
    "# Graph output\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "plt.bar(x=daily_data.index, height=daily_data.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9f7dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Good to see there are less missing values towards end of data \n",
    "# (meaning test and validation sets should be of better quality than train set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f1e5d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfefdd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Interpolate all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa206508",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import clean_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090747b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_data = clean_LSTM_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d6491",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create wind speed & direction vectors and misalignment to average wind farm vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6aa48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Average wind speeds & directions over the wind turbines\n",
    "wind_speeds = pd.DataFrame()\n",
    "nacelle_dir = pd.DataFrame()\n",
    "misalignment = pd.DataFrame()\n",
    "for idx, WTG_data in enumerate(data):\n",
    "    wind_speeds[idx] = WTG_data['Wind Speed']\n",
    "    nacelle_dir[idx] = WTG_data['Nacelle Orientation']\n",
    "    misalignment[idx] = WTG_data['Misalignment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed85d68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in misalignment:\n",
    "    misalignment[idx] = misalignment[idx].apply(lambda x: x if x <=180 else (360 - x)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0f3a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wind_dir = pd.DataFrame()\n",
    "for idx in misalignment:\n",
    "    wind_dir[idx] = nacelle_dir[idx] - misalignment[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3eb75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i in range(len(nacelle_dir.columns)):\n",
    "    row, col = i//5, i%5\n",
    "    axes[row,col].hist2d(wind_dir[i], wind_speeds[i], bins=(50, 50), vmax=400)\n",
    "    plt.xlabel('Wind Direction [deg]')\n",
    "    plt.ylabel('Wind Velocity [m/s]');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a27e1cb2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Creates data leakage!\n",
    "average = pd.DataFrame(index=nacelle_dir.index)\n",
    "average['wind_dir'] = wind_dir.mean(axis=1)\n",
    "average['wind_speeds'] = wind_speeds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca8afd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wind_X_vector = pd.DataFrame()\n",
    "wind_Y_vector = pd.DataFrame()\n",
    "for idx in wind_dir:\n",
    "    wind_dir[idx] = wind_dir[idx] * np.pi / 180 # convert to radians\n",
    "    wind_X_vector[idx] = wind_speeds[idx] * np.cos(wind_dir[idx])  # get X vector\n",
    "    wind_Y_vector[idx] = wind_speeds[idx] * np.sin(wind_dir[idx])  # get Y vector\n",
    "    wind_X_vector[idx] = wind_speeds[idx] * np.cos(wind_dir[idx])  # get X vector\n",
    "    wind_Y_vector[idx] = wind_speeds[idx] * np.sin(wind_dir[idx])  # get Y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ba4eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i in range(len(nacelle_dir.columns)):\n",
    "    row, col = i//5, i%5\n",
    "    axes[row,col].hist2d(wind_X_vector[i], wind_Y_vector[i], bins=(50, 50), vmax=400)\n",
    "    plt.xlabel('Wind X [m/s]')\n",
    "    plt.ylabel('Wind Y [m/s]');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a0dc160",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Creates data leakage!\n",
    "average['wind_dir_rad'] = average['wind_dir'] * np.pi / 180 # convert to radians\n",
    "average['X_vector'] = average['wind_speeds'] * np.cos(average['wind_dir_rad'])  # get X vector\n",
    "average['Y_vector'] = average['wind_speeds'] * np.sin(average['wind_dir_rad'])  # get Y vector"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43625e07",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.hist2d(average['wind_dir'], average['wind_speeds'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]');"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d023778",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.hist2d(average['X_vector'], average['Y_vector'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cf61b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx, WTG_data in enumerate(data):\n",
    "    WTG_data['WTG_wind_X'] = wind_X_vector[idx]\n",
    "    WTG_data['WTG_wind_Y'] = wind_Y_vector[idx]\n",
    "#     WTG_data['Misalign_wind_X'] = average['X_vector'] - wind_X_vector[idx] # Creates data leakage!\n",
    "#     WTG_data['Misalign_wind_Y'] = average['Y_vector'] - wind_Y_vector[idx] # Creates data leakage!\n",
    "    WTG_data.drop(columns=['Misalignment','Nacelle Orientation'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0d947",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Power vs. Rotor Speed check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d616a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = data[19].loc['2020-03-05':'2020-03-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c24ea8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.lineplot(x=temp.index, y=temp['Power']/150)\n",
    "sns.lineplot(x=temp.index, y=temp['Rotor Speed'])\n",
    "sns.lineplot(x=temp.index, y=temp['Wind Speed'])\n",
    "fig.legend(['Power','Rotor Speed', 'Wind Speed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9fd66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sine/Cosine Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656ecbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=data[0].index)\n",
    "timestamp_s = data[0].index.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5f7c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.iloc[0:792,0])\n",
    "plt.plot(df.iloc[0:792,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb50bd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for WTG_data in data:\n",
    "    WTG_data['Day sin'] = df['Day sin']\n",
    "    WTG_data['Day cos'] = df['Day cos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81f5bd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f303a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = data[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07858dc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd4169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611529ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_std = (df - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fae0fa17",
   "metadata": {
    "hidden": true
   },
   "source": [
    "column_indices = {name: i for i, name in enumerate(data[0].columns)}\n",
    "\n",
    "n = len(data[0])\n",
    "train_df = []\n",
    "val_df = []\n",
    "test_df = []\n",
    "\n",
    "for WTG_data in data:\n",
    "    train_df.append(WTG_data[0:int(n*0.7)])\n",
    "    val_df.append(WTG_data[int(n*0.7):int(n*0.9)])\n",
    "    test_df.append(WTG_data[int(n*0.9):])\n",
    "\n",
    "num_features = data[0].shape[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fc34d70",
   "metadata": {
    "hidden": true
   },
   "source": [
    "train_mean = train_df[0].mean()\n",
    "train_std = train_df[0].std()\n",
    "\n",
    "train_df = (train_df[0] - train_mean) / train_std\n",
    "val_df = (val_df[0] - train_mean) / train_std\n",
    "test_df = (test_df[0] - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4f991",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed954ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc9b83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcad2c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d38cb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ea3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79418af5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
    "                     label_columns=df.columns)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85227832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w2 = WindowGenerator(input_width=24*5*6, label_width=12*6, shift=12*6,\n",
    "                     label_columns=['Power'])\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96459fd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e32ef1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c8ad8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "w2.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa09975",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in w2.train.take(25):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f196224",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in w2.train.take(100):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7f653",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = w2.train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e0114",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for sequence in dataset:\n",
    "    sequence.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4f101",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023cbfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0b83b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb942d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create window\n",
    "n_steps_in =  24 * 6     # 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df[0], val_df[0], test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d9ba5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(data):\n",
    "    X_datasets = []\n",
    "    y_datasets = []\n",
    "    \n",
    "    for WTG_data in data:\n",
    "        \n",
    "        # Find sequences according to window size of X and y\n",
    "        WTG_data = np.array(WTG_data, dtype=np.float32)\n",
    "        WTG_sequences = tf.keras.utils.timeseries_dataset_from_array(data=WTG_data,\n",
    "                                                                    targets=None,\n",
    "                                                                    sequence_length=window.total_window_size,\n",
    "                                                                    sampling_rate=1,\n",
    "                                                                    sequence_stride=window.total_window_size,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    batch_size=32)\n",
    "        # Split X and y according to window size\n",
    "        WTG_sequences = WTG_sequences.map(window.split_window)\n",
    "        \n",
    "        # Transfer from tensor to numpy array to save under .NPY format\n",
    "        X_datasets.append(chain.from_iterable([X.numpy() for X, y in WTG_sequences]))\n",
    "        y_datasets.append(chain.from_iterable([y.numpy() for X, y in WTG_sequences]))\n",
    "        \n",
    "    # Aggregate WTGs batches into same array\n",
    "    X_array = np.array(list(chain.from_iterable(X_datasets)))\n",
    "    y_array = np.array(list(chain.from_iterable(y_datasets)))\n",
    "    \n",
    "    #X_array, y_array = shuffle_sequences(X_array, y_array)\n",
    "        \n",
    "    return X_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fb8a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "X_train, y_train = make_dataset(train_df)\n",
    "X_val, y_val = make_dataset(val_df)\n",
    "X_test, y_test = make_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd2579",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape}, Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abe95b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shuffle_sequences(X, y, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9fac9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_sequences(X_train, y_train, seed=1)\n",
    "X_val, y_val = shuffle_sequences(X_val, y_val, seed=2)\n",
    "X_test, y_test = shuffle_sequences(X_test, y_test, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a459df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape}, Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6f601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequence_name = f\"{window.input_width // 6}-{window.label_width//6}\"\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_train_{sequence_name}.npy', np.asanyarray(X_train, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_train_{sequence_name}.npy', np.asanyarray(y_train, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_val_{sequence_name}.npy', np.asanyarray(X_val, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_val_{sequence_name}.npy', np.asanyarray(y_val, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_X_test_{sequence_name}.npy', np.asanyarray(X_test, dtype=object))\n",
    "np.save(f'./projectwind/data/LSTM_sequence_y_test_{sequence_name}.npy', np.asanyarray(y_test, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3891b8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = np.load(f'./projectwind/data/LSTM_sequence_train_datasets.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ec03e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4551136",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in train_ds:\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689355cd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test of python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275230a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddd78",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11213ae8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5bf20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in =  24 * 6     # 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df[0], val_df[0], test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0512bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in window.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba4481",
   "metadata": {},
   "source": [
    "# LSTM_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f018a9",
   "metadata": {},
   "source": [
    "## Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6eb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 5 * 24 * 6     # 5 day x 24hrs x 6 periods of 10min\n",
    "n_steps_out = 12 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ff74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = window.train\n",
    "val_ds = window.val\n",
    "test_ds = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e424c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9432b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape},  Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43210b0d",
   "metadata": {},
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_datasets(n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910645d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create & Save 48h - 3hr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711deaa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9410f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c44162",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 5 day x 24hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    # 12hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0580a90f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d02c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verify dataset shapes\n",
    "print(f\"Train set shape:  X: {X_train.shape},  Y: {y_train.shape}\")\n",
    "print(f\"Val set shape:    X: {X_val.shape},  Y: {y_val.shape}\")\n",
    "print(f\"Test set shape:   X: {X_test.shape},  Y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec2ca9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.save_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142b6b3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d0d7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_lstm_model, multi_window)\n",
    "\n",
    "multi_val_performance = multi_lstm_model.evaluate(window.val)\n",
    "multi_performance = multi_lstm_model.evaluate(window.test, verbose=0)\n",
    "multi_window.plot(multi_lstm_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151995fe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM feedback_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dceb5f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        # First layer\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units) \n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True) #Wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        # Second layer\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        # Output layer\n",
    "        self.dense = tf.keras.layers.Dense(num_features)\n",
    "\n",
    "    def warmup(self, inputs):\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "        return prediction, state\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "\n",
    "        # Initialize the LSTM state.\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps.\n",
    "        for n in range(1, self.out_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "            # Add the prediction to the output.\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions\n",
    "\n",
    "    def compile_and_fit(model, window, patience=2):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        patience=patience,\n",
    "                                                        mode='min')\n",
    "\n",
    "        model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "        history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                          validation_data=window.val,\n",
    "                          callbacks=[early_stopping])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f44a7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for inputs, labels in window.train.take(1):\n",
    "    num_features = inputs.shape[2]\n",
    "    n_steps_in = inputs.shape[1]\n",
    "    n_steps_out = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd89ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=32, out_steps=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491763a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prediction, state = feedback_model.warmup(window.example[0])\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06dee5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model(window.example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2737a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Output shape (batch, time, features): ', feedback_model(window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db12f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "history = compile_and_fit(feedback_model, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e380d81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feedback_model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf64c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_performance = feedback_model.evaluate(window.val)\n",
    "test_performance = feedback_model.evaluate(window.test, verbose=0)\n",
    "window.plot(feedback_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95cb91",
   "metadata": {},
   "source": [
    "## Revising Window_Split to include forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "\n",
    "from projectwind.LSTM_weather_forecast import get_LSTM_data, WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5517258",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3020799",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scale datasets\n",
    "scaling_data = pd.DataFrame(index=['min','max'], columns=train_df[0].columns, data=0)\n",
    "for WTG_data in train_df:\n",
    "    for col in WTG_data:\n",
    "        temp_min = np.min([scaling_data.loc['min', col], WTG_data[col].min(axis=0)])\n",
    "        temp_max = np.max([scaling_data.loc['max', col], WTG_data[col].max(axis=0)])\n",
    "        scaling_data.loc['min', col] = temp_min\n",
    "        scaling_data.loc['max', col] = temp_max\n",
    "print(scaling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2469762",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apply scaling to all three datasets\n",
    "column_names = train_df[0].columns\n",
    "for WTGs in range(len(train_df)):\n",
    "    for col in column_names:\n",
    "        col_min = scaling_data.loc['min',col]\n",
    "        col_max = scaling_data.loc['max',col]\n",
    "        # Scale columns of each dataset\n",
    "        train_df[WTGs][col] = train_df[WTGs][col].apply(lambda x: (x - col_min) / (col_max - col_min))\n",
    "        val_df[WTGs][col] = val_df[WTGs][col].apply(lambda x: (x - col_min) / (col_max - col_min))\n",
    "        test_df[WTGs][col] = test_df[WTGs][col].apply(lambda x: (x - col_min) / (col_max - col_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8f62e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ff775",
   "metadata": {},
   "source": [
    "### Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c305eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 48   # hrs \n",
    "n_steps_out = 3   # hrs\n",
    "\n",
    "window = WindowGenerator(input_width=n_steps_in, label_width=n_steps_out, shift=n_steps_out,\n",
    "                         train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                         forecast_columns=['windSpeed_API','windGust_API',\n",
    "                                           'Wind_API_X','Wind_API_Y', \n",
    "                                           'WindGust_API_X', 'WindGust_API_Y'],\n",
    "                         label_columns=['Power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_fc_train, y_train, = window.make_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48830bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_fc_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_fc_val, y_val, = window.make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape, X_fc_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_fc_test, y_test, = window.make_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, X_fc_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e042ac7c",
   "metadata": {},
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df, val_df, test_df, \n",
    "                 forecast_columns=None, label_columns=None):\n",
    "\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df[0].columns)}\n",
    "        \n",
    "        # Work out the forecast column indices.\n",
    "        self.forecast_columns = forecast_columns\n",
    "        if forecast_columns is not None:\n",
    "            self.forecast_columns_indices = {name: i for i, name in enumerate(forecast_columns)}\n",
    "        self.forecast_indices = {name: i for i, name in enumerate(train_df[0].columns)}\n",
    "        \n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.forecast_width = label_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        # Work out window slices\n",
    "        self.total_window_size = input_width + shift\n",
    "        # Inputs\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        # Forecast\n",
    "        self.forecast_start = self.total_window_size - self.forecast_width\n",
    "        self.forecast_slice = slice(self.forecast_start, None)\n",
    "        self.forecast_indices = np.arange(self.total_window_size)[self.forecast_slice]\n",
    "        # Label\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Forecast column name(s): {self.forecast_columns}',            \n",
    "            f'Forecast indices: {self.forecast_indices}',\n",
    "            f'Label column name(s): {self.label_columns}',\n",
    "            f'Label indices: {self.label_indices}'])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd356807",
   "metadata": {},
   "source": [
    "def split_windows(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    forecast = features[:, self.forecast_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    \n",
    "    # If forecast & labels, stack window output together\n",
    "    if self.forecast_columns is not None:\n",
    "        forecast = tf.stack([forecast[:,:, self.column_indices[name]] for name in self.forecast_columns],\n",
    "                          axis=-1)\n",
    "    \n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack([labels[:,:, self.column_indices[name]] for name in self.label_columns],\n",
    "                          axis=-1)\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    forecast.set_shape([None, self.forecast_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, forecast, labels\n",
    "\n",
    "WindowGenerator.split_windows = split_windows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7480d3c",
   "metadata": {},
   "source": [
    "def make_dataset(self, data):\n",
    "    X_datasets = []\n",
    "    X_fc_datasets = []\n",
    "    y_datasets = []\n",
    "\n",
    "    for WTG_data in data:\n",
    "\n",
    "        # Find sequences according to window size of X and y\n",
    "        WTG_data = np.array(WTG_data, dtype=np.float32)\n",
    "        WTG_sequences = tf.keras.utils.timeseries_dataset_from_array(data=WTG_data,\n",
    "                                                                    targets=None,\n",
    "                                                                    sequence_length=self.total_window_size,\n",
    "                                                                    sampling_rate=1,\n",
    "                                                                    sequence_stride=self.total_window_size,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    batch_size=32)\n",
    "        # Split X and y according to window size\n",
    "        WTG_sequences = WTG_sequences.map(self.split_windows)\n",
    "\n",
    "        # Transfer from tensor to numpy array to save under .NPY format\n",
    "        X_datasets.append(chain.from_iterable([X.numpy() for X, X_fc, y in WTG_sequences]))\n",
    "        X_fc_datasets.append(chain.from_iterable([X_fc.numpy() for X, X_fc, y in WTG_sequences]))\n",
    "        y_datasets.append(chain.from_iterable([y.numpy() for X, X_fc, y in WTG_sequences]))\n",
    "\n",
    "    # Aggregate WTGs batches into same array\n",
    "    X_array = np.array(list(chain.from_iterable(X_datasets)))\n",
    "    X_fc_array = np.array(list(chain.from_iterable(X_fc_datasets)))\n",
    "    y_array = np.array(list(chain.from_iterable(y_datasets)))\n",
    "\n",
    "    X_array, X_fc_array, y_array = self.shuffle_sequences(X_array, X_fc_array, y_array)\n",
    "\n",
    "    return X_array, X_fc_array, y_array\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7556b67a",
   "metadata": {},
   "source": [
    "def shuffle_sequences(self, X, X_fc, y, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X_fc)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    return X, X_fc, y\n",
    "\n",
    "WindowGenerator.shuffle_sequences = shuffle_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d6125",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM model concat with weather forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726195a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926c442",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from projectwind.data import get_data\n",
    "from projectwind.LSTM_weather_forecast import get_LSTM_data, define_window, load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec353220",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6298a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df, 'Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b85aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split weather data from main dfs\n",
    "train_wf = list()\n",
    "for df in train_df:\n",
    "    train_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)\n",
    "\n",
    "val_wf = list()\n",
    "for df in val_df:\n",
    "    val_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)\n",
    "    \n",
    "test_wf = list()\n",
    "for df in test_df:\n",
    "    test_wf.append(df[['Wind Speed','Wind_X','Wind_Y']].copy())\n",
    "    df.drop(['Wind Speed','Wind_X', 'Wind_Y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffaea7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df, 'Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00aae2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e18db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_steps_in = 48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    #  3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_wf, val_wf, test_wf, 'Wind Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751758c3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_wf, y_train_wf = window.train\n",
    "X_val_wf, y_val_wf = window.val\n",
    "X_test_wf, y_test_wf = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b61b6a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def performance_model():\n",
    "    input_perf = tf.keras.layers.Input(shape=(n_steps_in, X_train.shape[2]))\n",
    "    x_state = tf.keras.layers.LSTM(32, return_sequences=True)(input_perf)\n",
    "    x_state = tf.keras.layers.LSTM(32, return_sequences=True)(x_state)\n",
    "    x = tf.keras.layers.LSTM(32, return_sequences=False)(x_state)\n",
    "    output_perf = tf.keras.layers.Dense(n_steps_out)(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_perf, outputs=output_perf)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a95b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf_model = performance_model()\n",
    "perf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8191c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def forecast_model():\n",
    "    input_fc = tf.keras.layers.Input(shape=(18,))  # Will only use y_forecast\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(input_fc)\n",
    "    output_fc = tf.keras.layers.Dense(18, activation=\"relu\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_fc, outputs=output_fc)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1d1c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc = forecast_model()\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb5a7b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Combined model\n",
    "model_perf = performance_model() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_perf = model_perf.input\n",
    "output_perf = model_perf.output\n",
    "\n",
    "model_fc = forecast_model() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_fc = model_fc.input\n",
    "output_fc = model_fc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8670029",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_perf, output_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22b4ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc, output_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b76bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Combine the two streams of data\n",
    "inputs = [input_perf, input_fc]\n",
    "\n",
    "combined = tf.keras.layers.concatenate([output_perf, output_fc])\n",
    "\n",
    "x = tf.keras.layers.Dense(n_steps_out, activation=\"relu\")(combined)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(n_steps_out, activation=\"linear\")(x)\n",
    "\n",
    "model_combined = tf.keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073962e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebb37f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c785c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train_wf2.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5427dd4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_wf2 = y_train_wf.reshape((289,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8238b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val.shape, y_val_wf.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405e090",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "model_perf.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "model_combined.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99c79e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model_combined.fit(x=[X_train, y_train_wf],y=y_train,\n",
    "                            epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6223f3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Combined Model _v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20d1a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e589d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hybrid_model():\n",
    "    input_perf = tf.keras.layers.Input(shape=(n_steps_in, X_train.shape[2]))\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(input_perf)\n",
    "    x_seq = tf.keras.layers.LSTM(32, return_sequences=True)(x_seq)\n",
    "    x_perf = tf.keras.layers.LSTM(32, return_sequences=False)(x_seq)\n",
    "    #x_perf = tf.keras.layers.Reshape((32*X_train.shape[1],))(x_perf)\n",
    "    input_fc = tf.keras.layers.Input(shape=(18,))\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(input_fc)\n",
    "    x_fc = tf.keras.layers.Dense(18, activation=\"relu\")(x)\n",
    "    \n",
    "    combined = tf.keras.layers.concatenate([x_perf, x_fc])\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(combined)\n",
    "    outputs = tf.keras.layers.Dense(n_steps_out, activation=\"linear\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_perf, input_fc], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b99222",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h_model=hybrid_model()\n",
    "h_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd0c6f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h_model.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da5b48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = h_model.fit(x=[X_train, y_train_wf],y=y_train,\n",
    "                            epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1364b2d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "866f73d4",
   "metadata": {},
   "source": [
    "# Weather forecast vs. On site measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206f08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba0d1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "\n",
    "from projectwind.LSTM_weather_forecast import get_LSTM_data, WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f8f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Fetching 25xWTG data ###\n",
      "### Fetching weather API data ###\n",
      "### Preparing datasets ###\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25bf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 48\n",
    "n_steps_out = 12\n",
    "window = WindowGenerator(input_width=n_steps_in, label_width=n_steps_out, shift=n_steps_out,\n",
    "                      train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                      forecast_columns=['windSpeed_API','windGust_API',\n",
    "                                        'Wind_API_X','Wind_API_Y', \n",
    "                                        'WindGust_API_X', 'WindGust_API_Y'],\n",
    "                      label_columns=['Power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8a5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 60\n",
       "Input column name(s): None\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
       "Forecast column name(s): ['windSpeed_API', 'windGust_API', 'Wind_API_X', 'Wind_API_Y', 'WindGust_API_X', 'WindGust_API_Y']\n",
       "Forecast indices: [48 49 50 51 52 53 54 55 56 57 58 59]\n",
       "Label column name(s): ['Power']\n",
       "Label indices: [48 49 50 51 52 53 54 55 56 57 58 59]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc563ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 16:05:37.025241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-16 16:05:37.057171: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-02-16 16:05:37.060444: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-16 16:05:37.061869: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_fc_train, y_train = window.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59485701",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df[0]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199b287",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(axes=ax, data=temp.corr(), cmap=\"YlGnBu\", annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cffd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "plt.plot(temp.loc['2019-06-05':'2019-06-15',['Wind Speed','windSpeed_API']]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44935c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc752f5b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tutorial LSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d3129",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_data import WindowGenerator, get_LSTM_data, define_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e2dfb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = get_LSTM_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0a810",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create window\n",
    "n_steps_in =  48 * 6     # 48hrs x 6 periods of 10min\n",
    "n_steps_out = 3 * 6    # 3hours x 6 periods of 10min\n",
    "window = define_window(n_steps_in, n_steps_out, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb182f80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "X_train, y_train = window.train\n",
    "X_val, y_val = window.val\n",
    "X_test, y_test = window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d72624",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_ex, y_ex = window.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3817ee09",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(input_shape=(n_steps_in, len(window.column_indices))),\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(n_steps_out),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([n_steps_out, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9683bf3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=5,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f563f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_lstm_model, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f03b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_performance = multi_lstm_model.evaluate(X_val, y_val)\n",
    "test_performance = multi_lstm_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc40e7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.plot(multi_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a187d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.trainer import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be811b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b721c8a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD - LSTM_data_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83085ccd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data = get_data(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ffe4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b933d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1986e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = clean_timesteps(raw_data)\n",
    "data = clean_LSTM_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caea234",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## clean_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad535dc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f13807",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_with_nan = temp_data[temp_data.isna().any(axis=1) == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cc9ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc[index_with_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972b773",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc['2019-05-06 09:30':'2019-05-06 15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9a11b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data.loc['2019-05-06 09:30':'2019-05-06 15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db529d7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for WTG_data in data:\n",
    "    print(WTG_data.isna().sum().sum())\n",
    "    WTG_data.interpolate(axis=0, inplace=True)\n",
    "    print(WTG_data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cebdc8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  split_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d769e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f337c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a7efa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_len = int(24 * 6 * 5.5)\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4834ce1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find number of seq possible\n",
    "seq_num = len(data[0]) // (720+72) # per turbine\n",
    "seq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3a476",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_seq_len = int(0.2 * seq_num) # last 20% indices will belong to test set\n",
    "val_seq_len  = int(0.2 * seq_num) # 2nd last 20% indices will belong to val set\n",
    "test_seq_len, val_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4310c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_seq_start = seq_num - test_seq_len\n",
    "val_seq_start = seq_num - test_seq_len - val_seq_len\n",
    "0, val_seq_start, test_seq_start, 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0901",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_idx_start = test_seq_start * seq_len\n",
    "val_idx_start = val_seq_start * seq_len\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556cd3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "test_idx_start = int((seq_num - (seq_num * 0.2)) * seq_len)\n",
    "val_idx_start = int((seq_num - (seq_num * 0.4)) * seq_len)\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e724a2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "seq_len = int(24 * 6 * 5.5)\n",
    "seq_num = len(data[0]) // (720+72) # per turbine\n",
    "test_idx_start = int(seq_num * (0.8 * seq_len))\n",
    "val_idx_start = int(seq_num * (0.6 * seq_len))\n",
    "val_idx_start, test_idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53debe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp.iloc[val_idx_start:test_idx_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b359763",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "from projectwind.LSTM_preproc import split_train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c45b6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, val, test = split_train_val_test_split(data, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaf9e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee999a16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## get_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d0d0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import get_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774fafb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences = get_sequences(train, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a1705",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b40cae",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## extract_target_from_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7388be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = {'train':[1,2,3], 'val':[4,5], 'test':[6,7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a099716",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = dict(train=[1,2,3], val=[4,5], test=[6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceef80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1d9d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name, data in datasets.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1013cf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import extract_target_from_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c36fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4127c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, Y = extract_target_from_sequences(sequences, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b5304",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## init_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdbb44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_preproc import init_LSTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79d80f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = init_LSTM_data(1, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4f16d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ac8b7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD - Trainer_LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfc605",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = np.load(f'./projectwind/data/LSTM_sequence_train_datasets.npy', allow_pickle=True)\n",
    "val_ds = np.load(f'./projectwind/data/LSTM_sequence_val_datasets.npy', allow_pickle=True)\n",
    "test_ds = np.load(f'./projectwind/data/LSTM_sequence_test_datasets.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baae5d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.LSTM_model import init_LSTM_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec718c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_LSTM_model(n_steps_in, n_steps_out, n_features):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
    "    model.add(Dense(n_steps_out, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='huber', metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a030f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = init_LSTM_model(n_steps_in=window.input_width, \n",
    "                        n_steps_out=window.label_width, \n",
    "                        n_features=len(window.column_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01646e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e9d69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b072991",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window.plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ef047",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MAE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(window.train,\n",
    "                    validation_data=window.val,\n",
    "                    epochs=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ead7ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e4577",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MSE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(window.train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=2,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332dbc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from projectwind.trainer import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89cb26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f14bfe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "298252f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1876b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d79e49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
